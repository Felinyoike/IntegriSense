{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304d636d-8a4d-4759-ae24-8aed70a4e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: scikit_learn in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit_learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit_learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit_learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (2.3.1)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Requirement already satisfied: xgboost in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn matplotlib pandas scikit_learn\n",
    "!pip install numpy\n",
    "!pip install imbalanced-learn\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b765fb-5636-459b-85d1-712aded36822",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53269ed9-d06d-418f-a970-9e33d7a3e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys: dict_keys(['signal', 'label', 'subject'])\n",
      "Keys inside 'signal': dict_keys(['chest', 'wrist'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = r\"C:\\Users\\PC\\Desktop\\INTEGRISENSE\\WESAD\\S2\\S2.pkl\"\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Show top-level keys\n",
    "print(\"Top-level keys:\", data.keys())\n",
    "\n",
    "# Show what's inside 'signal', if it exists\n",
    "if 'signal' in data:\n",
    "    print(\"Keys inside 'signal':\", data['signal'].keys())\n",
    "else:\n",
    "    print(\"No 'signal' key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9ff51b-82e2-4fc4-a6cb-73a289c3330c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chest signals: dict_keys(['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'])\n",
      "Wrist signals: dict_keys(['ACC', 'BVP', 'EDA', 'TEMP'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Chest signals:\", data['signal']['chest'].keys())\n",
    "print(\"Wrist signals:\", data['signal']['wrist'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50170df-2c9c-4311-9a6b-5bbd6a31ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded from wrist only:\n",
      "Shape of X: (1, 5)\n",
      "Feature vector: [[ 1.19436825e+01 -4.26828014e-04  3.91743329e-01  3.43869452e+01\n",
      "   6.34344863e+01]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def compute_hrv_rmssd(bvp_signal):\n",
    "    # Compute HRV using RMSSD from BVP (after smoothing)\n",
    "    diff = np.diff(bvp_signal)\n",
    "    squared_diff = np.square(diff)\n",
    "    rmssd = np.sqrt(np.mean(squared_diff))\n",
    "    return rmssd\n",
    "\n",
    "# Path to your file\n",
    "file_path = r\"C:\\Users\\PC\\Desktop\\INTEGRISENSE\\WESAD\\S2\\S2.pkl\"\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Get wrist signals\n",
    "wrist = data['signal']['wrist']\n",
    "bvp = wrist['BVP'].flatten()\n",
    "eda_wrist = wrist['EDA'].flatten()\n",
    "temp_wrist = wrist['TEMP'].flatten()\n",
    "acc_wrist = wrist['ACC']  # shape: (time, 3)\n",
    "\n",
    "# Feature 1: HRV (RMSSD) from BVP\n",
    "hrv_rmssd = compute_hrv_rmssd(bvp)\n",
    "\n",
    "# Feature 2: Mean BVP\n",
    "bvp_mean = np.mean(bvp)\n",
    "\n",
    "# Feature 3: Mean EDA\n",
    "eda_wrist_mean = np.mean(eda_wrist)\n",
    "\n",
    "# Feature 4: Mean TEMP\n",
    "temp_wrist_mean = np.mean(temp_wrist)\n",
    "\n",
    "# Feature 5: Mean magnitude of ACC\n",
    "acc_wrist_magnitude = np.linalg.norm(acc_wrist, axis=1)\n",
    "acc_wrist_mean_mag = np.mean(acc_wrist_magnitude)\n",
    "\n",
    "# Combine all 5 features into a single array\n",
    "X = np.array([[hrv_rmssd, bvp_mean, eda_wrist_mean, temp_wrist_mean, acc_wrist_mean_mag]])\n",
    "\n",
    "# Load labels (just for reference)\n",
    "y_raw = data['label']  # same length as original samples\n",
    "\n",
    "print(\"Features loaded from wrist only:\")\n",
    "print(f\"Shape of X: {X.shape}\")\n",
    "print(f\"Feature vector: {X}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47bfc10-c4d3-47c9-91ed-32d893c23498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of wrist signals from S2:\n",
      "     BVP       EDA   TEMP  ACC_X  ACC_Y  ACC_Z\n",
      "0 -59.37  1.138257  35.41   62.0  -21.0  107.0\n",
      "1 -53.42  1.125444  35.41   66.0   13.0   53.0\n",
      "2 -44.40  1.011405  35.41   41.0    9.0   15.0\n",
      "3 -33.17  1.033188  35.41   52.0   16.0   24.0\n",
      "4 -20.79  0.935807  35.41   54.0   15.0   34.0\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the pickle file\n",
    "file_path = r\"C:\\Users\\PC\\Desktop\\INTEGRISENSE\\WESAD\\S2\\S2.pkl\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "# Extract wrist signals\n",
    "wrist = data['signal']['wrist']\n",
    "\n",
    "# Flatten signals\n",
    "bvp = wrist['BVP'].flatten()\n",
    "eda = wrist['EDA'].flatten()\n",
    "temp = wrist['TEMP'].flatten()\n",
    "acc_x = wrist['ACC'][:, 0]\n",
    "acc_y = wrist['ACC'][:, 1]\n",
    "acc_z = wrist['ACC'][:, 2]\n",
    "\n",
    "# Get the minimum common length\n",
    "min_len = min(len(bvp), len(eda), len(temp), len(acc_x), len(acc_y), len(acc_z))\n",
    "\n",
    "# Truncate all signals to same length\n",
    "wrist_signals = {\n",
    "    'BVP': bvp[:min_len],\n",
    "    'EDA': eda[:min_len],\n",
    "    'TEMP': temp[:min_len],\n",
    "    'ACC_X': acc_x[:min_len],\n",
    "    'ACC_Y': acc_y[:min_len],\n",
    "    'ACC_Z': acc_z[:min_len],\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "wrist_df = pd.DataFrame(wrist_signals)\n",
    "\n",
    "# Show head of DataFrame\n",
    "print(\"Head of wrist signals from S2:\")\n",
    "print(wrist_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "991727a7-fef8-431f-8a64-4c4ba95c7208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S2: Loaded 1577 samples\n",
      "S3: Loaded 1509 samples\n",
      "S4: Loaded 1533 samples\n",
      "S5: Loaded 1605 samples\n",
      "S6: Loaded 1414 samples\n",
      "S7: Loaded 1900 samples\n",
      "S8: Loaded 1848 samples\n",
      "S9: Loaded 1910 samples\n",
      "S10: Loaded 1918 samples\n",
      "S11: Loaded 1947 samples\n",
      "S13: Loaded 1831 samples\n",
      "S14: Loaded 1836 samples\n",
      "S15: Loaded 1950 samples\n",
      "S16: Loaded 1804 samples\n",
      "S17: Loaded 1779 samples\n",
      "\n",
      "Final dataset shape:\n",
      "X: (26361, 4)\n",
      "y: (26361,)\n",
      "\n",
      "Label distribution after filtering and relabeling:\n",
      "Label 0: 16856 samples\n",
      "Label 1: 9505 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Path to the root WESAD dataset\n",
    "root_path = \"C:/Users/PC/Desktop/INTEGRISENSE/WESAD\"\n",
    "\n",
    "# Subjects to process (excluding S12, which doesn't exist)\n",
    "subjects = [f\"S{i}\" for i in range(2, 18) if i != 12]\n",
    "\n",
    "# Features to extract\n",
    "selected_features = ['EDA', 'TEMP', 'ACC', 'BVP']\n",
    "\n",
    "# Standard target sample length for downsampling\n",
    "target_length = 7000\n",
    "\n",
    "# Storage\n",
    "X, y = [], []\n",
    "\n",
    "for subj in subjects:\n",
    "    try:\n",
    "        file_path = os.path.join(root_path, subj, f\"{subj}.pkl\")\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f, encoding='latin1')\n",
    "\n",
    "        # Extract sensor signals and labels\n",
    "        signal = data['signal']['wrist']\n",
    "        label = data['label']\n",
    "\n",
    "        # Extract and downsample selected features\n",
    "        feature_arrays = []\n",
    "        for feature in selected_features:\n",
    "            values = signal[feature]\n",
    "            if feature == 'ACC':\n",
    "                # Flatten 3-axis ACC data\n",
    "                acc_magnitude = np.linalg.norm(values, axis=1)\n",
    "                values = acc_magnitude.reshape(-1, 1)\n",
    "            if values.shape[0] != target_length:\n",
    "                values = resample(values, target_length)\n",
    "            feature_arrays.append(values if values.ndim == 2 else values.reshape(-1, 1))\n",
    "\n",
    "        # Combine all features into one feature array\n",
    "        features = np.hstack(feature_arrays)\n",
    "\n",
    "        # Downsample and align labels to same length\n",
    "        label_array = label[:]\n",
    "        label_array = resample(label_array.reshape(-1, 1), target_length).astype(int).flatten()\n",
    "\n",
    "        # Filter out label 0 (undefined), keep 1=calm and 2=stress\n",
    "        mask = np.isin(label_array, [1, 2])\n",
    "        filtered_features = features[mask]\n",
    "        filtered_labels = label_array[mask]\n",
    "\n",
    "        # Relabel: 1 → 0 (calm), 2 → 1 (stress)\n",
    "        filtered_labels = np.where(filtered_labels == 1, 0, 1)\n",
    "\n",
    "        X.append(filtered_features)\n",
    "        y.append(filtered_labels)\n",
    "\n",
    "        print(f\"{subj}: Loaded {filtered_features.shape[0]} samples\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{subj}: Failed to process: {e}\")\n",
    "\n",
    "# Combine all subject data\n",
    "if X and y:\n",
    "    X = np.vstack(X)\n",
    "    y = np.concatenate(y)\n",
    "\n",
    "    print(\"\\nFinal dataset shape:\")\n",
    "    print(\"X:\", X.shape)\n",
    "    print(\"y:\", y.shape)\n",
    "\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(\"\\nLabel distribution after filtering and relabeling:\")\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"Label {label}: {count} samples\")\n",
    "else:\n",
    "    print(\"No data loaded. Please verify your dataset path and contents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf0ac60-15a6-49f4-ac0a-ecc8d82ead9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        EDA       TEMP    ACC_Mag        BVP  label\n",
      "0  1.585790  35.808589  65.824687  11.236238      0\n",
      "1  1.574424  35.825170  63.123662  26.610110      0\n",
      "2  1.525942  35.828855  62.771683  51.587284      0\n",
      "3  1.513203  35.829831  62.626886  27.933278      0\n",
      "4  1.497633  35.810250  62.588797  33.487841      0\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame to inspect head\n",
    "columns = ['EDA', 'TEMP', 'ACC_Mag', 'BVP']\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "df['label'] = y\n",
    "\n",
    "# Show head\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e82852-8b19-47cd-8704-9e58327e98e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0449bb48-659c-4fe2-92f9-2c72dc5687ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (1.15.3)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\pc\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a54aca-f5f3-4167-95cd-0505089001d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (2.3.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\pc\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from xgboost) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffce0ccf-98e5-4541-bab5-ad52d9aa5625",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:17:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.74      0.82      3372\n",
      "           1       0.65      0.86      0.74      1901\n",
      "\n",
      "    accuracy                           0.79      5273\n",
      "   macro avg       0.78      0.80      0.78      5273\n",
      "weighted avg       0.81      0.79      0.79      5273\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2511  861]\n",
      " [ 269 1632]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Replace this with your actual dataset\n",
    "# Ensure df is defined earlier in your notebook as your final combined data\n",
    "X = df[['EDA', 'TEMP', 'ACC_Mag', 'BVP']].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Step 1: Split the data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 4: Train using XGBoost\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Step 5: Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Optional: Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ac154fe-74ba-4559-8708-aefe1e9769c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: [13484 13484]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Class distribution after SMOTE:\", np.bincount(y_train_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26871fe9-8ff2-4839-a625-4ca6e5f1879a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Stressed\n"
     ]
    }
   ],
   "source": [
    "sample = [[0.9, 36.0, 3.2, 0.8]]  # Example input\n",
    "scaled_sample = scaler.transform(sample)\n",
    "predicted_label = model.predict(scaled_sample)\n",
    "print(\"Prediction:\", \"Stressed\" if predicted_label[0] == 1 else \"Calm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7287816e-e908-472b-a913-a8162ae0350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stress_detection_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model, \"stress_detection_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c7d2e-c643-407b-b2e2-ea893a6013da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
